{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twF1QJmy-5gP"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from PIL import Image\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "VCRUQEY5_JmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5VtC2InnHl_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceDataset(Dataset):\n",
        "    def __init__(self, root_dir, img_size=256):\n",
        "        self.root_dir = root_dir\n",
        "        self.img_size = img_size\n",
        "        self.pairs = []\n",
        "\n",
        "        # Collect all valid pairs\n",
        "        for identity in os.listdir(root_dir):\n",
        "            id_path = os.path.join(root_dir, identity)\n",
        "            if os.path.isdir(id_path):\n",
        "                front_dir = os.path.join(id_path, 'front_face')\n",
        "                side_dir = os.path.join(id_path, 'side_face')\n",
        "\n",
        "                if os.path.exists(front_dir) and os.path.exists(side_dir):\n",
        "                    fronts = [os.path.join(front_dir, f) for f in os.listdir(front_dir)\n",
        "                              if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "                    sides = [os.path.join(side_dir, f) for f in os.listdir(side_dir)\n",
        "                             if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "                    # Create all possible combinations\n",
        "                    self.pairs.extend([(s, f) for s in sides for f in fronts])\n",
        "\n",
        "        # GPU-optimized augmentations\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(img_size),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.ColorJitter(0.2, 0.2, 0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        side_path, front_path = self.pairs[idx]\n",
        "\n",
        "        # Efficient image loading\n",
        "        side_img = Image.open(side_path).convert('RGB')\n",
        "        front_img = Image.open(front_path).convert('RGB')\n",
        "\n",
        "        return {\n",
        "            'side': self.transform(side_img),\n",
        "            'front': self.transform(front_img)\n",
        "        }"
      ],
      "metadata": {
        "id": "DlY73frO_NNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNetGenerator(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3):\n",
        "        super().__init__()\n",
        "\n",
        "        def conv_block(in_ch, out_ch, down=True):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_ch, out_ch, 4, stride=2 if down else 1, padding=1, bias=False),\n",
        "                nn.InstanceNorm2d(out_ch),\n",
        "                nn.LeakyReLU(0.2) if down else nn.ReLU()\n",
        "            )\n",
        "\n",
        "        # Downsample\n",
        "        self.down1 = conv_block(in_channels, 64)\n",
        "        self.down2 = conv_block(64, 128)\n",
        "        self.down3 = conv_block(128, 256)\n",
        "        self.down4 = conv_block(256, 512)\n",
        "\n",
        "        # Upsample\n",
        "        self.up1 = conv_block(512, 256, down=False)\n",
        "        self.up2 = conv_block(512, 128, down=False)\n",
        "        self.up3 = conv_block(256, 64, down=False)\n",
        "        self.up4 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, out_channels, 4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Skip connections\n",
        "        d1 = self.down1(x)\n",
        "        d2 = self.down2(d1)\n",
        "        d3 = self.down3(d2)\n",
        "        d4 = self.down4(d3)\n",
        "\n",
        "        u1 = self.up1(d4)\n",
        "        u2 = self.up2(torch.cat([u1, d3], 1))\n",
        "        u3 = self.up3(torch.cat([u2, d2], 1))\n",
        "        return self.up4(torch.cat([u3, d1], 1))\n",
        "\n",
        "class PatchGANDiscriminator(nn.Module):\n",
        "    def __init__(self, in_channels=6):\n",
        "        super().__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1, bias=False),\n",
        "                nn.InstanceNorm2d(out_filters),\n",
        "                nn.LeakyReLU(0.2)\n",
        "            )\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            discriminator_block(in_channels, 64),\n",
        "            discriminator_block(64, 128),\n",
        "            discriminator_block(128, 256),\n",
        "            nn.Conv2d(256, 1, 4, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img_A, img_B):\n",
        "        return self.model(torch.cat([img_A, img_B], 1))"
      ],
      "metadata": {
        "id": "ubrxxydR_Sg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Initialize models\n",
        "    generator = UNetGenerator().to(device)\n",
        "    discriminator = PatchGANDiscriminator().to(device)\n",
        "\n",
        "    # Optimizers\n",
        "    g_optim = optim.Adam(generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "    d_optim = optim.Adam(discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "\n",
        "    # Loss functions\n",
        "    criterion_gan = nn.MSELoss()\n",
        "    criterion_l1 = nn.L1Loss()\n",
        "    lambda_l1 = 100\n",
        "\n",
        "    # Dataset and DataLoader\n",
        "    dataset = FaceDataset('/content/drive/MyDrive/output')\n",
        "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "    # Mixed precision training\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(100):\n",
        "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}\")\n",
        "        for batch in pbar:\n",
        "            real_side = batch['side'].to(device, non_blocking=True)\n",
        "            real_front = batch['front'].to(device, non_blocking=True)\n",
        "\n",
        "            # Train Discriminator\n",
        "            with autocast():\n",
        "                fake_front = generator(real_side)\n",
        "\n",
        "                # Real loss\n",
        "                pred_real = discriminator(real_side, real_front)\n",
        "                loss_real = criterion_gan(pred_real, torch.ones_like(pred_real))\n",
        "\n",
        "                # Fake loss\n",
        "                pred_fake = discriminator(real_side, fake_front.detach())\n",
        "                loss_fake = criterion_gan(pred_fake, torch.zeros_like(pred_fake))\n",
        "\n",
        "                d_loss = (loss_real + loss_fake) * 0.5\n",
        "\n",
        "            d_optim.zero_grad(set_to_none=True)\n",
        "            scaler.scale(d_loss).backward()\n",
        "            scaler.step(d_optim)\n",
        "\n",
        "            # Train Generator\n",
        "            with autocast():\n",
        "                fake_front = generator(real_side)\n",
        "\n",
        "                # GAN loss\n",
        "                pred_fake = discriminator(real_side, fake_front)\n",
        "                loss_gan = criterion_gan(pred_fake, torch.ones_like(pred_fake))\n",
        "\n",
        "                # L1 loss\n",
        "                loss_l1 = criterion_l1(fake_front, real_front) * lambda_l1\n",
        "\n",
        "                g_total_loss = loss_gan + loss_l1\n",
        "\n",
        "            g_optim.zero_grad(set_to_none=True)\n",
        "            scaler.scale(g_total_loss).backward()\n",
        "            scaler.step(g_optim)\n",
        "\n",
        "            scaler.update()\n",
        "\n",
        "            # Logging\n",
        "            pbar.set_postfix({'D Loss': d_loss.item(), 'G Loss': g_total_loss.item()})\n",
        "\n",
        "        # Save checkpoint\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            torch.save({\n",
        "                'generator': generator.state_dict(),\n",
        "                'discriminator': discriminator.state_dict(),\n",
        "                'epoch': epoch\n",
        "            }, f'checkpoint_epoch_{epoch+1}.pth')"
      ],
      "metadata": {
        "id": "_R-DYIG-_aWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "id": "JrQxQ1S1_gaS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}