{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "#import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Improved Generator (U-Net architecture for better results)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        # Example U-Net like architecture\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        u1 = self.up1(d2)\n",
    "        u2 = self.up2(u1)\n",
    "        return u2\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 1, 4, 1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 1, kernel_size=4, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset_get import CelebAPairedDataset\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1088718 valid image pairs\n",
      "Epoch [0/10] Batch [0/68045] Loss D_A: 0.5177501440048218, Loss D_B: 0.5173390507698059, Loss G: 1.8870849609375\n",
      "Epoch [0/10] Batch [500/68045] Loss D_A: 0.03433552756905556, Loss D_B: 0.060886166989803314, Loss G: 2.09153413772583\n",
      "Epoch [0/10] Batch [1000/68045] Loss D_A: 0.0007825492066331208, Loss D_B: 0.017512032762169838, Loss G: 2.325256109237671\n",
      "Epoch [0/10] Batch [1500/68045] Loss D_A: 0.0003827515465673059, Loss D_B: 0.056066982448101044, Loss G: 2.0809197425842285\n",
      "Epoch [0/10] Batch [2000/68045] Loss D_A: 0.0012499794829636812, Loss D_B: 0.014400693587958813, Loss G: 2.314405679702759\n",
      "Epoch [0/10] Batch [2500/68045] Loss D_A: 8.648333459859714e-05, Loss D_B: 0.016238341107964516, Loss G: 2.219290256500244\n",
      "Epoch [0/10] Batch [3000/68045] Loss D_A: 0.00520399771630764, Loss D_B: 0.00017489951278548688, Loss G: 2.2164101600646973\n",
      "Epoch [0/10] Batch [3500/68045] Loss D_A: 0.0002016467333305627, Loss D_B: 0.00011920143879251555, Loss G: 2.249157428741455\n",
      "Epoch [0/10] Batch [4000/68045] Loss D_A: 9.21365717658773e-05, Loss D_B: 0.0001224303850904107, Loss G: 2.219043254852295\n",
      "Epoch [0/10] Batch [4500/68045] Loss D_A: 0.00017546763410791755, Loss D_B: 0.004187050275504589, Loss G: 2.261770486831665\n",
      "Epoch [0/10] Batch [5000/68045] Loss D_A: 0.00010094790195580572, Loss D_B: 0.07619474083185196, Loss G: 1.8906567096710205\n",
      "Epoch [0/10] Batch [5500/68045] Loss D_A: 3.45719963661395e-05, Loss D_B: 0.08781368285417557, Loss G: 2.0360829830169678\n",
      "Epoch [0/10] Batch [6000/68045] Loss D_A: 1.2522787983471062e-05, Loss D_B: 0.02909545600414276, Loss G: 2.137178421020508\n",
      "Epoch [0/10] Batch [6500/68045] Loss D_A: 9.001626494864468e-06, Loss D_B: 0.18656454980373383, Loss G: 2.206284523010254\n",
      "Epoch [0/10] Batch [7000/68045] Loss D_A: 4.9026464694179595e-05, Loss D_B: 0.07541216164827347, Loss G: 2.191439151763916\n",
      "Epoch [0/10] Batch [7500/68045] Loss D_A: 0.00016196207434404641, Loss D_B: 0.019398748874664307, Loss G: 2.204604148864746\n",
      "Epoch [0/10] Batch [8000/68045] Loss D_A: 0.0013151484308764338, Loss D_B: 0.015376103110611439, Loss G: 2.186429738998413\n",
      "Epoch [0/10] Batch [8500/68045] Loss D_A: 3.064064003410749e-05, Loss D_B: 0.08904600888490677, Loss G: 1.8729363679885864\n",
      "Epoch [0/10] Batch [9000/68045] Loss D_A: 0.0003056483983527869, Loss D_B: 0.0318102166056633, Loss G: 2.0754151344299316\n",
      "Epoch [0/10] Batch [9500/68045] Loss D_A: 2.23545193875907e-05, Loss D_B: 0.07458113133907318, Loss G: 2.008852243423462\n",
      "Epoch [0/10] Batch [10000/68045] Loss D_A: 0.00010379518062109128, Loss D_B: 0.19920453429222107, Loss G: 1.705183506011963\n",
      "Epoch [0/10] Batch [10500/68045] Loss D_A: 2.676077747310046e-05, Loss D_B: 0.08860510587692261, Loss G: 1.9610108137130737\n",
      "Epoch [0/10] Batch [11000/68045] Loss D_A: 0.05006588622927666, Loss D_B: 0.06675495207309723, Loss G: 1.985746145248413\n",
      "Epoch [0/10] Batch [11500/68045] Loss D_A: 6.443780148401856e-05, Loss D_B: 0.08498448133468628, Loss G: 1.953336238861084\n",
      "Epoch [0/10] Batch [12000/68045] Loss D_A: 0.0002917574893217534, Loss D_B: 0.0843377336859703, Loss G: 1.8479363918304443\n",
      "Epoch [0/10] Batch [12500/68045] Loss D_A: 1.81346622412093e-05, Loss D_B: 0.14641022682189941, Loss G: 1.9056710004806519\n",
      "Epoch [0/10] Batch [13000/68045] Loss D_A: 6.0853944887639955e-06, Loss D_B: 0.07487061619758606, Loss G: 2.0468552112579346\n",
      "Epoch [0/10] Batch [13500/68045] Loss D_A: 2.444537130941171e-06, Loss D_B: 0.08581052720546722, Loss G: 1.8472731113433838\n",
      "Epoch [0/10] Batch [14000/68045] Loss D_A: 7.830345566617325e-06, Loss D_B: 0.12673337757587433, Loss G: 1.923798680305481\n",
      "Epoch [0/10] Batch [14500/68045] Loss D_A: 4.7750745579833165e-06, Loss D_B: 0.23489300906658173, Loss G: 1.5748790502548218\n",
      "Epoch [0/10] Batch [15000/68045] Loss D_A: 7.946339610498399e-05, Loss D_B: 0.0704084262251854, Loss G: 2.027670383453369\n",
      "Epoch [0/10] Batch [15500/68045] Loss D_A: 0.0001987525902222842, Loss D_B: 0.17185860872268677, Loss G: 2.074294328689575\n",
      "Epoch [0/10] Batch [16000/68045] Loss D_A: 2.7865713491337374e-05, Loss D_B: 0.15372595191001892, Loss G: 1.9578793048858643\n",
      "Epoch [0/10] Batch [16500/68045] Loss D_A: 1.829487518989481e-05, Loss D_B: 0.057819925248622894, Loss G: 1.9496679306030273\n",
      "Epoch [0/10] Batch [17000/68045] Loss D_A: 1.361627710139146e-05, Loss D_B: 0.06857746839523315, Loss G: 1.8733155727386475\n",
      "Epoch [0/10] Batch [17500/68045] Loss D_A: 1.92978168342961e-05, Loss D_B: 0.05987633019685745, Loss G: 1.9853678941726685\n",
      "Epoch [0/10] Batch [18000/68045] Loss D_A: 1.6724352462915704e-05, Loss D_B: 0.17137059569358826, Loss G: 2.0725905895233154\n",
      "Epoch [0/10] Batch [18500/68045] Loss D_A: 1.823246384446975e-05, Loss D_B: 0.17797145247459412, Loss G: 2.0208377838134766\n",
      "Epoch [0/10] Batch [19000/68045] Loss D_A: 1.139377764047822e-05, Loss D_B: 0.07866734266281128, Loss G: 1.988260269165039\n",
      "Epoch [0/10] Batch [19500/68045] Loss D_A: 0.006957666482776403, Loss D_B: 0.08995939791202545, Loss G: 1.8878355026245117\n",
      "Epoch [0/10] Batch [20000/68045] Loss D_A: 2.8172639758849982e-06, Loss D_B: 0.1468392014503479, Loss G: 2.01985502243042\n",
      "Epoch [0/10] Batch [20500/68045] Loss D_A: 1.8626185919856653e-05, Loss D_B: 0.2681267261505127, Loss G: 1.936060905456543\n",
      "Epoch [0/10] Batch [21000/68045] Loss D_A: 1.3427709291136125e-06, Loss D_B: 0.12112722545862198, Loss G: 1.9285383224487305\n",
      "Epoch [0/10] Batch [21500/68045] Loss D_A: 1.4423172615352087e-05, Loss D_B: 0.07823994010686874, Loss G: 1.9343745708465576\n",
      "Epoch [0/10] Batch [22000/68045] Loss D_A: 1.3714629858441185e-05, Loss D_B: 0.19025492668151855, Loss G: 1.7842353582382202\n",
      "Epoch [0/10] Batch [22500/68045] Loss D_A: 1.8141565305995755e-05, Loss D_B: 0.11070708185434341, Loss G: 1.9193822145462036\n",
      "Epoch [0/10] Batch [23000/68045] Loss D_A: 1.192575837194454e-05, Loss D_B: 0.10457412153482437, Loss G: 1.8353885412216187\n",
      "Epoch [0/10] Batch [23500/68045] Loss D_A: 5.11844109496451e-06, Loss D_B: 0.12140990048646927, Loss G: 2.034575939178467\n",
      "Epoch [0/10] Batch [24000/68045] Loss D_A: 2.6379837436252274e-05, Loss D_B: 0.040034107863903046, Loss G: 1.938100814819336\n",
      "Epoch [0/10] Batch [24500/68045] Loss D_A: 0.00036283605732023716, Loss D_B: 0.07122956961393356, Loss G: 1.8480441570281982\n",
      "Epoch [0/10] Batch [25000/68045] Loss D_A: 3.071098035434261e-05, Loss D_B: 0.04489097744226456, Loss G: 1.9852453470230103\n",
      "Epoch [0/10] Batch [25500/68045] Loss D_A: 3.448956340434961e-05, Loss D_B: 0.022903257980942726, Loss G: 2.0015032291412354\n",
      "Epoch [0/10] Batch [26000/68045] Loss D_A: 3.3585847631911747e-06, Loss D_B: 0.16014482080936432, Loss G: 1.641615867614746\n",
      "Epoch [0/10] Batch [26500/68045] Loss D_A: 2.0704019334516488e-05, Loss D_B: 0.056624870747327805, Loss G: 2.0003557205200195\n",
      "Epoch [0/10] Batch [27000/68045] Loss D_A: 8.279210305772722e-06, Loss D_B: 0.0373949371278286, Loss G: 2.0614349842071533\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (side_img, front_img) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;66;03m# Move images to MPS device\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m         side_img \u001b[38;5;241m=\u001b[39m \u001b[43mside_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m         front_img \u001b[38;5;241m=\u001b[39m front_img\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;66;03m# Train Generators\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize dataset and dataloader\n",
    "    dataset = CelebAPairedDataset(root_dir='/Volumes/Vids/CelebA/output', transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "    # Initialize models\n",
    "    G_A2B = Generator().to(device)\n",
    "    G_B2A = Generator().to(device)\n",
    "    D_A = Discriminator().to(device)\n",
    "    D_B = Discriminator().to(device)\n",
    "\n",
    "    # Define optimizers\n",
    "    optimizer_G = optim.Adam(list(G_A2B.parameters()) + list(G_B2A.parameters()), lr=0.0002, betas=(0.5, 0.999))\n",
    "    optimizer_D_A = optim.Adam(D_A.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    optimizer_D_B = optim.Adam(D_B.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "    # Loss functions\n",
    "    criterion_GAN = nn.MSELoss().to(device)\n",
    "    criterion_cycle = nn.L1Loss().to(device)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (side_img, front_img) in enumerate(dataloader):\n",
    "            # Move images to MPS device\n",
    "            side_img = side_img.to(device)\n",
    "            front_img = front_img.to(device)\n",
    "\n",
    "            # Train Generators\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            # Generate fake front and side images\n",
    "            fake_front = G_A2B(side_img)\n",
    "            fake_side = G_B2A(front_img)\n",
    "\n",
    "            # Adversarial loss\n",
    "            loss_GAN_A2B = criterion_GAN(D_B(fake_front), torch.ones_like(D_B(fake_front)))\n",
    "            loss_GAN_B2A = criterion_GAN(D_A(fake_side), torch.ones_like(D_A(fake_side)))\n",
    "\n",
    "            # Cycle consistency loss\n",
    "            reconstructed_side = G_B2A(fake_front)\n",
    "            reconstructed_front = G_A2B(fake_side)\n",
    "            loss_cycle_A = criterion_cycle(reconstructed_side, side_img)\n",
    "            loss_cycle_B = criterion_cycle(reconstructed_front, front_img)\n",
    "\n",
    "            # Total generator loss\n",
    "            loss_G = loss_GAN_A2B + loss_GAN_B2A + loss_cycle_A + loss_cycle_B\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            # Train Discriminator A\n",
    "            optimizer_D_A.zero_grad()\n",
    "            loss_D_A = criterion_GAN(D_A(side_img), torch.ones_like(D_A(side_img))) + \\\n",
    "                       criterion_GAN(D_A(fake_side.detach()), torch.zeros_like(D_A(fake_side.detach())))\n",
    "            loss_D_A.backward()\n",
    "            optimizer_D_A.step()\n",
    "\n",
    "            # Train Discriminator B\n",
    "            optimizer_D_B.zero_grad()\n",
    "            loss_D_B = criterion_GAN(D_B(front_img), torch.ones_like(D_B(front_img))) + \\\n",
    "                       criterion_GAN(D_B(fake_front.detach()), torch.zeros_like(D_B(fake_front.detach())))\n",
    "            loss_D_B.backward()\n",
    "            optimizer_D_B.step()\n",
    "\n",
    "            # Print losses and save images every 100 iterations\n",
    "            if i % 500 == 0:\n",
    "                print(f'Epoch [{epoch}/{num_epochs}] Batch [{i}/{len(dataloader)}] '\n",
    "                      f'Loss D_A: {loss_D_A.item()}, Loss D_B: {loss_D_B.item()}, Loss G: {loss_G.item()}')\n",
    "\n",
    "                # Save generated images\n",
    "                with torch.no_grad():\n",
    "                    fake_front = G_A2B(side_img)\n",
    "                    fake_side = G_B2A(front_img)\n",
    "\n",
    "                    # Denormalize images for saving\n",
    "                    def denormalize(tensor):\n",
    "                        return tensor * 0.5 + 0.5\n",
    "\n",
    "                    save_image(denormalize(fake_front.cpu()), f'generated_images/epoch_{epoch}_batch_{i}_fake_front.png')\n",
    "                    save_image(denormalize(side_img.cpu()), f'generated_images/epoch_{epoch}_batch_{i}_real_side.png')\n",
    "                    save_image(denormalize(fake_side.cpu()), f'generated_images/epoch_{epoch}_batch_{i}_fake_side.png')\n",
    "                    save_image(denormalize(front_img.cpu()), f'generated_images/epoch_{epoch}_batch_{i}_real_front.png')\n",
    "\n",
    "    # Save models\n",
    "    torch.save(G_A2B.state_dict(), 'G_A2B.pth')\n",
    "    torch.save(G_B2A.state_dict(), 'G_B2A.pth')\n",
    "    torch.save(D_A.state_dict(), 'D_A.pth')\n",
    "    torch.save(D_B.state_dict(), 'D_B.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
